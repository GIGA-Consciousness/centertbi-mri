{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XNAT unique values extractor\n",
    "This notebook walk through all objects in a XNAT database to extract all possible fields and all possible values.\n",
    "Please edit login.cfg with your credentials before executing this script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Creation: 07/2017 by Stephen Larroque\n",
    "#\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import lxml\n",
    "import xml.etree.ElementTree as ET\n",
    "import pyxnat\n",
    "import re\n",
    "\n",
    "#try:\n",
    "import ujson as json # fast json lib\n",
    "#except ImportError:\n",
    "#    import json # native json lib\n",
    "\n",
    "# For out-of-core computing (ie, to store the dict on disk and thus avoid MemoryOverflow error)\n",
    "from libs.chest import Chest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### HELPER FUNCTIONS\n",
    "from copy import deepcopy\n",
    "from libs.xmlpp import get_pprint as xml_pprint\n",
    "def get_raw_xml(elements_list):\n",
    "    '''Get the source xml of a list of lxml elements or pyxnat objects'''\n",
    "    # Convert to a list of elements if it's a single element (to ease looping)\n",
    "    if not isinstance(elements_list, list):\n",
    "        elements_list = [elements_list]\n",
    "\n",
    "    out = ''\n",
    "    for i, element in enumerate(elements_list):\n",
    "        out += '\\n=== Element %i\\n' % i\n",
    "        # If this is an XML element\n",
    "        if isinstance(element, lxml.etree._Element):\n",
    "            # Make a copy of the element because we will modify it\n",
    "            e = deepcopy(element)\n",
    "            # Strip comments, else lxml does not know how to print the XML\n",
    "            lxml.etree.strip_tags(e, lxml.etree.Comment)\n",
    "            # Add the XML of this element to the output\n",
    "            out += xml_pprint(lxml.etree.tostring(e, pretty_print=True))\n",
    "            #print(lxml.etree.tostring(e, pretty_print=True)) #debug\n",
    "        # pyxnat object, we just fetch the xml from the server\n",
    "        if isinstance(element, pyxnat.core.resources.EObject):\n",
    "            out += element.get()\n",
    "        # Print differently if this is any other type\n",
    "        else:\n",
    "            out += repr(element)\n",
    "    return out\n",
    "\n",
    "def pprint_xml(obj):\n",
    "    print(xml_pprint(get_raw_xml(obj)))\n",
    "\n",
    "#### HELPER GLOBALS\n",
    "# XNAT namespace (to use with lxml xpath queries)\n",
    "xnatns = {'arc': 'http://nrg.wustl.edu/arc',\n",
    " 'cat': 'http://nrg.wustl.edu/catalog',\n",
    " 'ext': 'http://nrg.wustl.edu/ext',\n",
    " 'pipe': 'http://nrg.wustl.edu/pipe',\n",
    " 'prov': 'http://www.nbirn.net/prov',\n",
    " 'scr': 'http://nrg.wustl.edu/scr',\n",
    " 'val': 'http://nrg.wustl.edu/val',\n",
    " 'wrk': 'http://nrg.wustl.edu/workflow',\n",
    " 'xdat': 'http://nrg.wustl.edu/security',\n",
    " 'xnat': 'http://nrg.wustl.edu/xnat',\n",
    " 'xnat_a': 'http://nrg.wustl.edu/xnat_assessments',\n",
    " 'xsi': 'http://www.w3.org/2001/XMLSchema-instance'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connection to XNAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading login infos\n",
    "cfgpath = os.path.join(os.getcwd(), 'login.cfg')\n",
    "with open(cfgpath) as f:\n",
    "    login_infos = json.load(f)\n",
    "\n",
    "# Connect to XNAT db\n",
    "central = pyxnat.Interface(server=\"http://tbixnat.incf.org:8080\", user=login_infos['username'], password=login_infos['password'], cachedir='/tmp')\n",
    "# Add schemas (allows to use .attrs() to get list of attributes)\n",
    "central.manage.schemas.add('xnat/xnat.xsd')\n",
    "\n",
    "# Get list of all centers\n",
    "centers = central.select.projects()\n",
    "print(centers.get())\n",
    "\n",
    "# Select center (constraining to one center for the moment)\n",
    "# TODO: loop over all centers\n",
    "#cULgData_Liege_project = central.select.project('LIE')\n",
    "\n",
    "# Show structure of project\n",
    "central.inspect.structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj = centers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = sum(1 for _ in centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(get_raw_xml(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from libs.tqdm import tqdm_notebook\n",
    "\n",
    "def rec_merge(a, b, path=None, robust=False):\n",
    "    \"\"\"Recursively merges dict b into a\n",
    "    Kudos to Andrew Cooke: https://stackoverflow.com/a/7205107/1121352\"\"\"\n",
    "    if path is None: path = []\n",
    "    for key in b:\n",
    "        if key in a:\n",
    "            if isinstance(a[key], dict) and isinstance(b[key], dict):\n",
    "                rec_merge(a[key], b[key], path + [str(key)], robust)\n",
    "            elif isinstance(a[key], set) and isinstance(b[key], set):\n",
    "                a[key].update(b[key])\n",
    "            elif a[key] == b[key]:\n",
    "                pass # same leaf value\n",
    "            else:\n",
    "                # Conflict: if robust, we create a new array key+'_conflicts' and we either try to merge with a previously conflicting type but same as b[key], or if b[key] is of an unseen type yet, we just create a new entry for this type\n",
    "                if robust:\n",
    "                    ckey = key+'_conflicts'\n",
    "                    # Never had any conflict for this key, just create a conflicts array\n",
    "                    if not ckey in a:\n",
    "                        a[ckey] = []\n",
    "                        a[ckey].append(b[key])\n",
    "                    # Else there were already conflicts in the past for this key\n",
    "                    else:\n",
    "                        #raise Exception('Warning: rec_merge encountered a conflict in %s' % ('/'.join(path)+'/'+str(key)))\n",
    "                        # Try to find a previous conflict of the same type to merge\n",
    "                        found_compatible_type = False\n",
    "                        for cid in xrange(len(a[ckey])):\n",
    "                            conflict = a[ckey][cid]\n",
    "                            if type(conflict) == type(b[key]):\n",
    "                                if isinstance(conflict, dict):\n",
    "                                    rec_merge(a[ckey][cid], b[key], path + [str(ckey)], robust)\n",
    "                                else:\n",
    "                                    a[ckey][cid].update(b[key])\n",
    "                                found_compatible_type = True\n",
    "                        # This type was never seen before, we add this conflict type\n",
    "                        if not found_compatible_type:\n",
    "                            a[ckey].append(b[key])\n",
    "                # Else, display an exception\n",
    "                else:\n",
    "                    print(key, a[key], b[key], type(a[key]), type(b[key]))\n",
    "                    raise Exception('Conflict at %s' % '.'.join(path + [str(key)]))\n",
    "        else:\n",
    "            a[key] = b[key]\n",
    "    return a\n",
    "\n",
    "def walkthrough(xnatobjlist, namespaces=None, outofcore=False, firstonly=False, level=0, progress_maxlevel=2, debug=False):\n",
    "    if not hasattr(xnatobjlist, '__iter__'):\n",
    "        xnatobjlist = [xnatobjlist]\n",
    "    # Out of core computing using chest to store on disk rather than in-memory (to avoid MemoryOverflow error)\n",
    "    if outofcore and level == 0 and maxmem > 0:\n",
    "        chest = Chest(path=os.path.join(os.getcwd(), 'uniquevalschest_level%i' % level))\n",
    "        chest['projects'] = {}\n",
    "        out = chest['projects']\n",
    "        out['id'] = set()\n",
    "        out['label'] = set()\n",
    "        out['datatype'] = set()\n",
    "        out['text'] = set()\n",
    "        out['attributes'] = {}\n",
    "        out['subelements'] = {}\n",
    "        out['children'] = {}\n",
    "    else:\n",
    "        if level == 0:\n",
    "            chest = {}\n",
    "            chest['projects'] = {}\n",
    "            out = chest['projects']\n",
    "        else:\n",
    "            out = {}\n",
    "        out.update({'id': set(),\n",
    "                    'label': set(),\n",
    "                    'datatype': set(),\n",
    "                    'text': set(),\n",
    "                    'attributes': {},\n",
    "                    'subelements': {},\n",
    "                    'children': {}\n",
    "                   })\n",
    "    # prepare namespaces for attribute search\n",
    "    if namespaces:\n",
    "        namespaces_filt = dict()\n",
    "        for val, key in namespaces.items():\n",
    "            namespaces_filt['{'+key+'}'] = val+':'\n",
    "\n",
    "    # prepare for progress display\n",
    "    # count\n",
    "    count = sum(1 for _ in xnatobjlist) # count total number of items (to predict time and display progress)\n",
    "    if firstonly and count > firstonly:\n",
    "        count = firstonly\n",
    "    # current object type name\n",
    "    try:\n",
    "        if hasattr(xnatobjlist, 'tag') and isinstance(xnatobjlist.tag, str):\n",
    "            curtype = re.sub('{.*}', '', xnatobjlist.tag)\n",
    "        else:\n",
    "            obj = str(type(xnatobjlist[0]))\n",
    "            curtype = obj[obj.rfind('.')+1:obj.rfind(\"'\")]\n",
    "    except StopIteration as exc:\n",
    "        curtype = ''\n",
    "        pass\n",
    "\n",
    "    # Limit the progress display, because there is currently a memory leak of ipywidgets, old widgets stay in memory\n",
    "    if progress_maxlevel <= 0:\n",
    "        xnatobjlist_iterator = xnatobjlist\n",
    "    else:\n",
    "        if level < progress_maxlevel:\n",
    "            xnatobjlist_iterator = tqdm_notebook(xnatobjlist, total=count, desc=curtype, position=level, leave=False)\n",
    "        else:\n",
    "            xnatobjlist_iterator = xnatobjlist\n",
    "\n",
    "    i = 0\n",
    "    # Main loop: for each item in the list\n",
    "    for obj in xnatobjlist_iterator:\n",
    "        # Continue to the next object?\n",
    "        if firstonly:\n",
    "            if i >= firstonly:\n",
    "                break\n",
    "        # Debug print\n",
    "        if debug: print(obj)\n",
    "        # add id and label\n",
    "        if hasattr(obj, 'id'):\n",
    "            out['id'].add(obj.id())\n",
    "        if hasattr(obj, 'label'):\n",
    "            out['label'].add(obj.label())\n",
    "        if hasattr(obj, 'datatype'):\n",
    "            out['datatype'].add(obj.datatype())\n",
    "        if hasattr(obj, 'text') and obj.text:\n",
    "            out['text'].add(obj.text.strip())\n",
    "        # Only if not a resource nor a file, else it's only about files so no xml content\n",
    "        if not isinstance(obj, (pyxnat.core.resources.Resource, pyxnat.core.resources.File)):\n",
    "            # Attributes\n",
    "            attrs = obj.xpath('@*')\n",
    "            for attr in attrs:\n",
    "                # Get attribute's xml name and value\n",
    "                attrname = attr.attrname\n",
    "                if namespaces: # if namespaces is provided, we can use that to replace the prefix (else attributes don't provide the prefix, only subelements do)\n",
    "                    #if attrname.startswith('{'): print(attrname)\n",
    "                    for key, val in namespaces_filt.items():\n",
    "                        #if attrname.startswith('{'): print(key, val)\n",
    "                        attrname = attrname.replace(key, val)\n",
    "                    #print('lala'+attrname)\n",
    "                attrval = str(attr)\n",
    "                # Create a unique set for this attribute\n",
    "                if not attrname in out['attributes']:\n",
    "                    out['attributes'][attrname] = set()\n",
    "                # Add this value (the set will make sure it is unique)\n",
    "                out['attributes'][attrname].add( attrval )\n",
    "            # Subelements\n",
    "            subelts = obj.xpath('*')\n",
    "            for subelt in subelts:\n",
    "                # Get subelement's xml name\n",
    "                if subelt.prefix:\n",
    "                    prefix = (subelt.prefix + ':')\n",
    "                else:\n",
    "                    prefix = ''\n",
    "                subeltname = prefix + re.sub('{.*}', '', subelt.tag)\n",
    "                # Get subelement's value\n",
    "                if hasattr(subelt, 'text'):\n",
    "                    subeltval = subelt.text\n",
    "                else:\n",
    "                    subeltval = str(subelt)\n",
    "                if subeltval: # remove useless chars at the start and end\n",
    "                    subeltval = subeltval.strip()\n",
    "                # Recursive call if it has children\n",
    "                if subelt.getchildren() or subelt.xpath('@*'): # subelt.getchildren() == subelt.xpath('*')\n",
    "                    # Create a dict for this subelement\n",
    "                    if not subeltname in out['subelements']:\n",
    "                        out['subelements'][subeltname] = dict()\n",
    "                    cval = walkthrough([subelt], namespaces=namespaces, firstonly=firstonly, level=level+1, debug=debug)\n",
    "                    # Merge with our dict\n",
    "                    rec_merge(out['subelements'][subeltname], cval, robust=True)\n",
    "                else:\n",
    "                    # Create a unique set for this subelement\n",
    "                    if not subeltname in out['subelements']:\n",
    "                        out['subelements'][subeltname] = set()\n",
    "                    # Add this value (the set will make sure it is unique)\n",
    "                    out['subelements'][subeltname].add( subeltval )\n",
    "        # Children\n",
    "        if hasattr(obj, 'children'):\n",
    "            for childname in obj.children():\n",
    "                # Call the method to retrieve children from child name\n",
    "                child = getattr(obj, childname)()\n",
    "                # Recursive call\n",
    "                cres = walkthrough(child, namespaces=namespaces, firstonly=firstonly, level=level+1, debug=debug)\n",
    "                # Merge with our dict\n",
    "                if not childname in out['children']:\n",
    "                    out['children'][childname] = {}\n",
    "                rec_merge(out['children'][childname], cres, robust=True)\n",
    "        # Flush to disk\n",
    "        if outofcore and level == 0:\n",
    "            chest.flush()\n",
    "        # Increment counter for firstonly\n",
    "        i += 1\n",
    "    if level == 0:\n",
    "        return chest\n",
    "    else:\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = walkthrough(centers, namespaces=xnatns, firstonly=2, outofcore=False, debug=False)\n",
    "print('All Done!')\n",
    "# TODO: MAYBE: if again we get memory errors, chest and shelve and other dbs are useless here because they work only on first-level because they all pickle, so any 2nd level will need to be loaded fully in memory. Also chest cannot store changed values (hence update not working).\n",
    "# So need to flatten the dict: create a custom dict that uses internally shelve, that does proper assignment when .append by using setitem instead and use xpath-like paths 'item1/item2' instead of ['item1']['item2'] to flatten the whole dict and allow easy insertion in shelve or any other db like hdf5 etc.\n",
    "# for inspiration to flatten dict, see:\n",
    "# * https://github.com/gmr/flatdict\n",
    "# * https://github.com/bunbun/nested-dict\n",
    "# for db insertion, see:\n",
    "# * shelve\n",
    "# * sqlite_object\n",
    "# *hdf5pys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Just a little sanity check\n",
    "try:\n",
    "    assert len(out['projects']['children']['subjects']['children']['experiments']['children']['scans']['subelements']['xnat:parameters']['subelements']['xnat:voxelRes']['attributes']['x']) > 1\n",
    "    print('Sanity check OK!')\n",
    "except AssertionError as exc:\n",
    "    print('ERROR: xnat:parameters has only 1 sample set of values, probably something went wrong (or you used firstonly=1)')\n",
    "    out['projects']['children']['subjects']['children']['experiments']['children']['scans']['subelements']['xnat:parameters']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the result into a json file\n",
    "import pickle as pk\n",
    "if isinstance(out, Chest):\n",
    "    with open(out.key_to_filename('projects'), 'rb') as e:\n",
    "        with open('db_unique_values.json', 'w') as f:\n",
    "            json.dump({'projects': pk.load(e)}, f, ensure_ascii=False, indent=4, sort_keys=True)\n",
    "else:\n",
    "    with open('db_unique_values.json', 'w') as f:\n",
    "        json.dump(out, f, ensure_ascii=False, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_xpath(obj, path):\n",
    "    a = obj\n",
    "    for p in path.split('/'):\n",
    "        a = a[p]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_xpath(out, 'projects/children/subjects/subelements/xnat:experiments/subelements/xnat:experiment/subelements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show the result\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "### Unused code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class SortedDict(OrderedDict):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SortedDict, self).__init__()\n",
    "\n",
    "        for key, value in sorted(kwargs.items()):\n",
    "            if isinstance(value, dict):\n",
    "                self[key] = SortedDict(**value)\n",
    "            else:\n",
    "                self[key] = value\n",
    "\n",
    "sorted_dict = SortedDict(**a)\n",
    "sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = obj.xpath('*')\n",
    "b2 = b[0]\n",
    "b2.text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key, val = ('{http://www.w3.org/2001/XMLSchema-instance}', 'xsi:')\n",
    "s = '{http://www.w3.org/2001/XMLSchema-instance}schemaLocation'\n",
    "s.replace(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj.id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = obj.subject('CTBI_S00638').experiment('CTBI_E02818').scan('2').resource('3144').file('DTI.bval')\n",
    "g.attributes()\n",
    "type(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scans = central.select.project('HEL').subject('CTBI_S00800').experiment('CTBI_E04816').scans()\n",
    "scan = scans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pprint_xml((scan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = scan.xpath('*')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_children = param.getchildren()\n",
    "param_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param.xpath('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "walkthrough(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pprint_xml(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from libs.xmltodict import xmltodict\n",
    "xmltodict.parse(get_raw_xml(param).encode('utf-8'), process_namespaces=True, namespaces=xnatns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a = {'a': set([1, 2]), 'b': {1, 2}, 'c': {'d': set([1, 2])}}\n",
    "b = {'a': set([1, 4]), 'b': {1, 3}, 'c': {'d': set([1, 3, 4])}}\n",
    "c = merge(a, b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c['a'].add(4)\n",
    "c['b'].add(3)\n",
    "c['b'].add(4)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = set([1, 2])\n",
    "e.update(set([1, 3]))\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from libs.sqlite_object import SqliteDict\n",
    "a = SqliteDict(filename='test.sqlite3', persist=True)\n",
    "a['label'] = set([1,2,3])\n",
    "a['id'] = a['label']\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {
    "03707d30ddb64a1bb63dc7dff45a8250": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "2ba9911f4c3a436ca856608363d3d11d": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "2bd749f04e4442b1af5403fa1116deef": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "43a7aa3cb4eb4362b8b2f3ac84702457": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "57b76c22e4674176b3bf271124b91cc4": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "696953d3e6a34ff5a86fa4ad4177552f": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "bc353e4a7f2847509e10d62f76bf32e6": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "bcf02ad9e0ae4fb1b6c8ea0313c55b28": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    },
    "be7138af44cd4ca799a8513657983e0b": {
     "views": [
      {
       "cell_index": 10
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
