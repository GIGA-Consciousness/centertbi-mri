{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import shelve\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "\n",
    "PY3 = (sys.version_info >= (3,0))\n",
    "\n",
    "if PY3:\n",
    "    _zip = zip\n",
    "else:\n",
    "    import itertools\n",
    "    _zip = itertools.izip\n",
    "\n",
    "\n",
    "__version__ = '0.5.2'\n",
    "\n",
    "\n",
    "class fdict(dict):\n",
    "    '''Flattened nested dict, all items are settable and gettable through ['item1']['item2'] standard form or ['item1/item2'] internal form.\n",
    "    This allows to replace the internal dict with any on-disk storage system like a shelve's shelf (great for huge nested dicts that cannot fit into memory).\n",
    "    Main limitation: an entry can be both a singleton and a nested fdict: when an item is a singleton, you can setitem to replace to a nested dict, but if it is a nested dict and you setitem it to a singleton, both will coexist. Except for fastview mode, there is no way to know if a nested dict exists unless you walk through all items, which would be too consuming for a simple setitem. In this case, a getitem will always return the singleton, but nested leaves can always be accessed via items() or by direct access (eg, x['a/b/c']).\n",
    "    \n",
    "    Fastview mode: remove conflicts issue and allow for fast O(m) contains(), delete() and view*() (such as vieitems()) where m in the number of subitems, instead of O(n) where n was the total number of elements in the fdict(). Downside is setitem() being O(m) too because of nodes metadata building, and memory/storage overhead, since we store all nodes and leaves lists in order to allow for fast lookup.\n",
    "    '''\n",
    "    def __init__(self, d=None, rootpath='', delimiter='/', fastview=False, **kwargs):\n",
    "        # Init self parameters\n",
    "        self.rootpath = rootpath\n",
    "        self.delimiter = delimiter\n",
    "        self.fastview = fastview\n",
    "        self.kwargs = kwargs  # store all kwargs for easy subclassing\n",
    "\n",
    "        if d is not None:\n",
    "            if rootpath:\n",
    "                # Internal call, we get a subdict, we just create a new fdict with the same dictionary but with a restricted rootpath\n",
    "                if isinstance(d, dict):\n",
    "                    self.d = d\n",
    "                else:\n",
    "                    # sometimes (particularly extract(fullpath=True)) we get a list of tuples instead of a dict\n",
    "                    self.d = dict(d)\n",
    "            elif isinstance(d, self.__class__):\n",
    "                # We were supplied a fdict, initialize a copy\n",
    "                self.d = d.copy().d\n",
    "            elif isinstance(d, dict):\n",
    "                # Else it is not an internal call, the user supplied a dict to initialize the fdict, we have to flatten its keys\n",
    "                self.d = self.flatkeys(d, sep=delimiter)\n",
    "                if self.fastview:\n",
    "                    self._build_metadata(list(self._generickeys(self.d)))\n",
    "            else:\n",
    "                # Else the user supplied another type of object, we try to convert to a dict and flatten it\n",
    "                self.d = self.flatkeys(dict(d), sep=delimiter)\n",
    "                if self.fastview:\n",
    "                    self._build_metadata(list(self._generickeys(self.d)))\n",
    "        else:\n",
    "            # No dict supplied, create an empty dict\n",
    "            self.d = dict()\n",
    "\n",
    "        # Call compatibility layer\n",
    "        self._viewkeys, self._viewvalues, self._viewitems = self._getitermethods(self.d)\n",
    "\n",
    "    @staticmethod\n",
    "    def _getitermethods(d):\n",
    "        '''Defines what function to use to access the internal dictionary items most efficiently depending on Python version'''\n",
    "        if PY3:\n",
    "            # Py3\n",
    "            _viewkeys = d.keys\n",
    "            _viewvalues = d.values\n",
    "            _viewitems = d.items\n",
    "        else:\n",
    "            # Py2\n",
    "            if getattr(d, 'viewvalues', None):\n",
    "                # Py2.7\n",
    "                _viewkeys = d.viewkeys\n",
    "                _viewvalues = d.viewvalues\n",
    "                _viewitems = d.viewitems\n",
    "            else:\n",
    "                # Py2.6\n",
    "                _viewkeys = d.iterkeys\n",
    "                _viewvalues = d.itervalues\n",
    "                _viewitems = d.iteritems\n",
    "        return _viewkeys, _viewvalues, _viewitems\n",
    "\n",
    "    def _generickeys(self, d):\n",
    "        return self._getitermethods(d)[0]()\n",
    "\n",
    "    def _genericitems(self, d):\n",
    "        return self._getitermethods(d)[2]()\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_all_parent_nodes(path, delimiter='/'):\n",
    "        '''Get path to all parent nodes for current leaf, starting from leaf's direct parent down to root'''\n",
    "        pos = path.rfind(delimiter)\n",
    "        i = 0\n",
    "        while pos != -1:\n",
    "            yield path[:pos+1]\n",
    "            pos = path.rfind(delimiter, 0, pos)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_all_parent_nodes_nested(path, delimiter='/'):\n",
    "        '''Get path to all parent nodes for current leaf, starting from root down to leaf's direct parent, and return only the relative key (not the fullkey)'''\n",
    "        pos = path.find(delimiter)\n",
    "        i = 0\n",
    "        lastpos = 0\n",
    "        while pos != -1:\n",
    "            yield path[lastpos:pos]\n",
    "            lastpos = pos+1\n",
    "            pos = path.find(delimiter, pos+1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_parent_node(path, delimiter='/'):\n",
    "        '''Get path to the first parent of current leaf'''\n",
    "        endpos = len(path)  # 'a/b' (leaf)\n",
    "        if path.endswith(delimiter):  # 'a/b/' (node)\n",
    "            endpos -= 1\n",
    "        return path[:path.rfind(delimiter, 0, endpos)+1]\n",
    "\n",
    "    @staticmethod\n",
    "    def flatkeys(d, sep=\"/\"):\n",
    "        \"\"\"\n",
    "        Flatten a dictionary: build a new dictionary from a given one where all\n",
    "        non-dict values are left untouched but nested ``dict``s are recursively\n",
    "        merged in the new one with their keys prefixed by their parent key.\n",
    "\n",
    "        >>> flatkeys({1: 42, 'foo': 12})\n",
    "        {1: 42, 'foo': 12}\n",
    "        >>> flatkeys({1: 42, 'foo': 12, 'bar': {'qux': True}})\n",
    "        {1: 42, 'foo': 12, 'bar.qux': True}\n",
    "        >>> flatkeys({1: {2: {3: 4}}})\n",
    "        {'1.2.3': 4}\n",
    "        >>> flatkeys({1: {2: {3: 4}, 5: 6}})\n",
    "        {'1.2.3': 4, '1.5': 6}\n",
    "\n",
    "        v0.1.0 by bfontaine, MIT license\n",
    "        \"\"\"\n",
    "        flat = {}\n",
    "        dicts = [(\"\", d)]\n",
    "\n",
    "        while dicts:\n",
    "            prefix, d = dicts.pop()\n",
    "            for k, v in d.items():\n",
    "                k_s = str(k)\n",
    "                if isinstance(v, collections.Mapping):\n",
    "                    dicts.append((\"%s%s%s\" % (prefix, k_s, sep), v))\n",
    "                else:\n",
    "                    k_ = prefix + k_s if prefix else k\n",
    "                    flat[k_] = v\n",
    "        return flat\n",
    "\n",
    "    def _build_path(self, key='', prepend=None):\n",
    "        '''Build full path of current key given the rootpath and optionally a prepend'''\n",
    "        return (self.delimiter).join(filter(None, [prepend, self.rootpath, key]))\n",
    "\n",
    "    def _build_metadata(self, fullkeys):\n",
    "        '''Build metadata to make viewitem and other methods using item resolution faster.\n",
    "        Provided a list of full keys, this method will build parent nodes to point all the way down to the leaves.\n",
    "        Only for fastview and fastview2 modes.'''\n",
    "\n",
    "        if self.fastview:\n",
    "            for fullkey in fullkeys:\n",
    "                if not fullkey.endswith(self.delimiter):\n",
    "                    # Fastview mode: create additional entries for each parent at every depths of the current leaf\n",
    "                    parents = self._get_all_parent_nodes(fullkey, self.delimiter)\n",
    "\n",
    "                    # First parent stores the direct path to the leaf\n",
    "                    # Then we recursively add the path to the nested parent in all super parents.\n",
    "                    lastparent = fullkey\n",
    "                    for parent in parents:\n",
    "                        if parent in self.d:\n",
    "                            # There is already a parent entry, we add to the set\n",
    "                            self.d.__getitem__(parent).add(lastparent)\n",
    "                        else:\n",
    "                            # Else we create a set and add this child\n",
    "                            self.d.__setitem__(parent, set([lastparent]))\n",
    "                        lastparent = parent\n",
    "        else:\n",
    "            # No fastview: we still build a parent node with a counter, so we know the number of items below\n",
    "            # Each node will contain an integer, the number of direct descendant nodes and/or leaves\n",
    "            # Create an empty entry for the parent element, so that we can quickly know if there are children for this key\n",
    "            # Format is d['item1/'], with the ending delimiter\n",
    "            for fullkey in fullkeys:\n",
    "                if not fullkey.endswith(self.delimiter):\n",
    "                    # Get list of parent nodes\n",
    "                    parents = self._get_all_parent_nodes(fullkey, self.delimiter)\n",
    "                    # All nodes will store the total number of subelements at any level, this is because if we store only direct descendants only then x['a/b/d'] and x['a/b/e'] will produce x['a/'] == 1 and that is wrong because then we cannot know how to decrement x['a/'] and when we can delete it.\n",
    "                    for parent in parents:\n",
    "                        if parent in self.d:\n",
    "                            self.d[parent] += 1\n",
    "                        else:\n",
    "                            self.d.__setitem__(parent, 1)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        '''Get an item given the key. O(1) in any case: if the item is a leaf, direct access, else if it is a node, a new fdict will be returned with a different rootpath but sharing the same internal dict.'''\n",
    "        # Node or leaf?\n",
    "        if key in self.d: # Leaf: return the value (leaf direct access test is why we do `in self.d` and not `in self`)\n",
    "            return self.d.__getitem__(key)\n",
    "        else: # Node: return a new full fdict based on the old one but with a different rootpath to limit the results by default (this is the magic that allows compatibility with the syntax d['item1']['item2'])\n",
    "            return self.__class__(d=self.d, rootpath=self._build_path(key), delimiter=self.delimiter, fastview=self.fastview, **self.kwargs)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        '''Set an item given the key. Supports for direct setting of nested elements without prior dict(), eg, x['a/b/c'] = 1. O(1) to set the item. If fastview mode, O(m*l) because of metadata building where m is the number of parents of current leaf, and l the number of leaves (if provided a nested dict).'''\n",
    "        # TODO: fastview mode can setitem buildmetadata in O(2*(l+m)) linear time instead of O(l*m) quadratic time by first walking nodes and leafs of input dict and finally just merge the nodes sets with self.d, so we walk each parent only once, instead of walking each leaf and then each parent of each leaf repetitively.\n",
    "        # Build the fullkey\n",
    "        fullkey = self._build_path(key)\n",
    "\n",
    "        # Store the item\n",
    "        if isinstance(value, dict):\n",
    "            # if the value is a dict, flatten it recursively or drop if empty\n",
    "\n",
    "            # First we need to delete the previous value if it was a singleton\n",
    "            if fullkey in self.d:\n",
    "                self.__delitem__(key)\n",
    "\n",
    "            # Flatten dict and store its leaves\n",
    "            if not value:\n",
    "                # User supplied an empty dict, the user wants to create a subdict, but it is not necessary here since nested dict are supported by default, just need to assign nested values\n",
    "                return\n",
    "            else:\n",
    "                # else not empty dict\n",
    "                if isinstance(value, self.__class__):\n",
    "                    # If it is the same class as this, we merge\n",
    "                    self.update(self.__class__({key: value}))\n",
    "                else:\n",
    "                    # If this is just a normal dict, we flatten it and merge\n",
    "                    d2 = self.flatkeys({self._build_path(prepend=key) : value}, sep=self.delimiter)\n",
    "                    self.d.update(d2)\n",
    "                    if self.fastview:\n",
    "                        self._build_metadata(self._generickeys(d2))\n",
    "        else:\n",
    "            # if the value is not a dict, we consider it a singleton/leaf, and we just build the full key and store the value as is\n",
    "            if self.fastview:\n",
    "                # Fastview mode: can ensure no conflict with a nested dict by managing the metadata\n",
    "                dirkey = fullkey+self.delimiter\n",
    "                # This key was a nested dict\n",
    "                if dirkey in self.d:\n",
    "                    # If this key was a nested dict before, we need to delete it recursively (with all subelements) and also delete pointer from parent node\n",
    "                    self.__delitem__(key)\n",
    "                # This key did not exist before but a parent is a singleton\n",
    "                parents = self._get_all_parent_nodes(fullkey)\n",
    "                for parent in parents:\n",
    "                    parentleaf = parent[:len(parent)-1]\n",
    "                    if parentleaf in self.d:\n",
    "                        self.__delitem__(parentleaf)\n",
    "                # Then we can rebuild the metadata to point to this new leaf\n",
    "                self._build_metadata([fullkey])\n",
    "            # and finally add the singleton as a leaf\n",
    "            self.d.__setitem__(fullkey, value)\n",
    "\n",
    "    def __delitem__(self, key):\n",
    "        '''Delete an item in the internal dict, O(1) for any leaf, O(n) for a nested dict'''\n",
    "        fullkey = self._build_path(key)\n",
    "        if fullkey in self.d:\n",
    "            # Key is a leaf, we can directly delete it\n",
    "            if self.fastview:\n",
    "                # Remove current node from its parent node's set()\n",
    "                parentnode = self._get_parent_node(fullkey, self.delimiter)\n",
    "                if parentnode: # if the node is not 1st-level (because then the parent is the root, it's then a fdict, not a set)\n",
    "                    self.d.__getitem__(parentnode).remove(fullkey)\n",
    "                    if not self.d.__getitem__(parentnode):\n",
    "                        # if the set is now empty, just delete the node (to signal that there is nothing below now)\n",
    "                        self.__delitem__(parentnode)  # recursive delete because the node is referenced by its parent\n",
    "            # Delete the item!\n",
    "            return self.d.__delitem__(fullkey)\n",
    "        else:\n",
    "            # Else there is no direct match, but might be a nested dict, we have to walk through all the dict\n",
    "            dirkey = fullkey+self.delimiter\n",
    "            flagdel = False\n",
    "            if self.fastview:\n",
    "                # Fastview mode: use the fast recursive viewkeys(), which will access the supplied node and walk down through all nested elements to build the list of items to delete, without having to walk the whole dict (only the subelements pointed by the current key and the subsubelements of the subkeys etc.)\n",
    "                # Note that we ovveride the rootpath of viewkeys, because if delitem is called on a nested element (eg, del x['a']['b']), then the rootpath is the parent, so we will walk through all parent elements when we need only to walk from the child (the current node key), so this is both an optimization and also bugfix (because else we get a different behaviour if we use del x['a/b'] and del x['a']['b'])\n",
    "                keystodel = [k for k in self.viewkeys(fullpath=True, nodes=True, rootpath=fullkey)]\n",
    "                # We can already delete the current node key\n",
    "                if dirkey in self.d:\n",
    "                    self.d.__delitem__(dirkey)\n",
    "                    flagdel = True\n",
    "                # Remove current node from its parent node's set()\n",
    "                parentnode = self._get_parent_node(dirkey, self.delimiter)\n",
    "                if parentnode: # if the node is not 1st-level (because then the parent is the root, it's then a fdict, not a set)\n",
    "                    self.d.__getitem__(parentnode).remove(dirkey)\n",
    "                    if not self.d.__getitem__(parentnode):\n",
    "                        # if the set is now empty, just delete the node (to signal that there is nothing below now)\n",
    "                        self.__delitem__(parentnode)  # recursive delete because the node is referenced by its parent\n",
    "            else:\n",
    "                # Walk through all items in the dict and delete the nodes or nested elements starting from the supplied node (if any)\n",
    "                keystodel = [k for k in self._viewkeys() if k.startswith(dirkey)]  # TODO: try to optimize with a generator instead of a list, but with viewkeys the dict is changing at the same time so we get runtime error!\n",
    "\n",
    "            # Delete all matched keys\n",
    "            for k in keystodel:\n",
    "                self.d.__delitem__(k)\n",
    "\n",
    "            # Check if we deleted at least one key, else raise a KeyError exception\n",
    "            if not keystodel and not flagdel:\n",
    "                raise KeyError(key)\n",
    "            else:\n",
    "                return\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        '''Check existence of a key (or subkey) in the dictionary. O(1) for any leaf, O(n) at worst for nested dicts (eg, 'a' in d with d['a/b'] defined)'''\n",
    "        fullkey = self._build_path(key)\n",
    "        if self.d.__contains__(fullkey):\n",
    "            # Key is a singleton/leaf, there is a direct match\n",
    "            return True\n",
    "        else:\n",
    "            dirkey = fullkey+self.delimiter\n",
    "            if self.fastview:\n",
    "                # Fastview mode: nodes are stored so we can directly check in O(1)\n",
    "                return self.d.__contains__(dirkey)\n",
    "            else:\n",
    "                # Key might be a node, but we have to check all items\n",
    "                for k in self.viewkeys():\n",
    "                    if k.startswith(dirkey):\n",
    "                        return True\n",
    "                return False\n",
    "\n",
    "    def viewkeys(self, fullpath=False, nodes=False, rootpath=None):\n",
    "        if not rootpath:\n",
    "            # Allow to override rootpath, particularly useful for delitem (which is always called from parent, so the rootpath is incorrect, overriding the rootpath allows to limit the search breadth)\n",
    "            rootpath = self.rootpath\n",
    "\n",
    "        if not rootpath:\n",
    "            if self.fastview:\n",
    "                for k in self._viewkeys():\n",
    "                    if not k.endswith(self.delimiter) or nodes:\n",
    "                        yield k\n",
    "            else:\n",
    "                for k in self._viewkeys():\n",
    "                    yield k\n",
    "        else:\n",
    "            pattern = rootpath+self.delimiter\n",
    "            lpattern = len(pattern) if not fullpath else 0 # return the shortened path or fullpath?\n",
    "            if self.fastview:\n",
    "                # Fastview mode\n",
    "                if pattern in self.d:\n",
    "                    children = set()\n",
    "                    children.update(self.d.__getitem__(pattern).copy())\n",
    "                    while children:\n",
    "                        child = children.pop()\n",
    "                        if child.endswith(self.delimiter):\n",
    "                            # Node, append all the subchildren to the stack\n",
    "                            children.update(self.d.__getitem__(child))\n",
    "                            if nodes:\n",
    "                                yield child[lpattern:]\n",
    "                        else:\n",
    "                            # Leaf, return the key and value\n",
    "                            yield child[lpattern:]\n",
    "            else:\n",
    "                for k in (k[lpattern:] for k in self._viewkeys() if k.startswith(pattern)):\n",
    "                    yield k\n",
    "\n",
    "    def viewitems(self, fullpath=False, nodes=False, rootpath=None):\n",
    "        if not rootpath:\n",
    "            # Allow to override rootpath, particularly useful for delitem (which is always called from parent, so the rootpath is incorrect, overriding the rootpath allows to limit the search breadth)\n",
    "            rootpath = self.rootpath\n",
    "\n",
    "        if not rootpath:\n",
    "            # Return all items (because no rootpath, so no filter)\n",
    "            if self.fastview:\n",
    "                # Fastview mode, filter out nodes (ie, keys ending with delimiter) to keep only leaves\n",
    "                for k,v in self._viewitems():\n",
    "                    if not k.endswith(self.delimiter) or nodes:\n",
    "                        yield k,v\n",
    "            else:\n",
    "                # No fastview, just return the internal dict's items\n",
    "                for k,v in self._viewitems():\n",
    "                    yield k,v\n",
    "        else:\n",
    "            # Else with rootpath, filter items to keep only the ones below the rootpath level\n",
    "            # Prepare the pattern (the rootpath + delimiter) to filter items keys\n",
    "            pattern = rootpath+self.delimiter\n",
    "            lpattern = len(pattern) if not fullpath else 0 # return the shortened path or fullpath?\n",
    "            if self.fastview:\n",
    "                # Fastview mode, get the list of items directly from the current entry, and walk recursively all children to get down to the leaves\n",
    "                if pattern in self.d:\n",
    "                    children = set()\n",
    "                    children.update(self.d.__getitem__(pattern))\n",
    "                    while children:\n",
    "                        child = children.pop()\n",
    "                        if child.endswith(self.delimiter):\n",
    "                            # Node, append all the subchildren to the stack\n",
    "                            children.update(self.d.__getitem__(child))\n",
    "                            if nodes:\n",
    "                                yield child[lpattern:], self.d.__getitem__(child)\n",
    "                        else:\n",
    "                            # Leaf, return the key and value\n",
    "                            yield child[lpattern:], self.d.__getitem__(child)\n",
    "            else:\n",
    "                # No fastview, just walk through all items and filter out the ones that are not in the current rootpath\n",
    "                for k,v in ((k[lpattern:], v) for k,v in self._viewitems() if k.startswith(pattern)):\n",
    "                    yield k,v\n",
    "\n",
    "    def viewvalues(self, nodes=False, rootpath=None):\n",
    "        if not rootpath:\n",
    "            # Allow to override rootpath, particularly useful for delitem (which is always called from parent, so the rootpath is incorrect, overriding the rootpath allows to limit the search breadth)\n",
    "            rootpath = self.rootpath\n",
    "\n",
    "        if not rootpath:\n",
    "            if self.fastview:\n",
    "                for k,v in self._viewitems():\n",
    "                    if not k.endswith(self.delimiter) or nodes:\n",
    "                        yield v\n",
    "            else:\n",
    "                for v in self._viewvalues():\n",
    "                    yield v\n",
    "        else:\n",
    "            pattern = rootpath+self.delimiter\n",
    "            if self.fastview:\n",
    "                # Fastview mode\n",
    "                if pattern in self.d:\n",
    "                    children = set()\n",
    "                    children.update(self.d.__getitem__(pattern))\n",
    "                    while children:\n",
    "                        child = children.pop()\n",
    "                        if child.endswith(self.delimiter):\n",
    "                            # Node, append all the subchildren to the stack\n",
    "                            children.update(self.d.__getitem__(child))\n",
    "                            if nodes:\n",
    "                                yield self.d.__getitem__(child)\n",
    "                        else:\n",
    "                            # Leaf, return the key and value\n",
    "                            yield self.d.__getitem__(child)\n",
    "            else:\n",
    "                for v in (v for k,v in self._viewitems() if k.startswith(pattern)):\n",
    "                    yield v\n",
    "\n",
    "    iterkeys = viewkeys\n",
    "    itervalues = viewvalues\n",
    "    iteritems = viewitems\n",
    "    if PY3:\n",
    "        keys = viewkeys\n",
    "        values = viewvalues\n",
    "        items = viewitems\n",
    "    else:\n",
    "        def keys(self, *args, **kwargs):\n",
    "            return list(self.viewkeys(*args, **kwargs))\n",
    "        def values(self, *args, **kwargs):\n",
    "            return list(self.viewvalues(*args, **kwargs))\n",
    "        def items(self, *args, **kwargs):\n",
    "            return list(self.viewitems(*args, **kwargs))\n",
    "\n",
    "    def update(self, d2):\n",
    "        if isinstance(d2, self.__class__):\n",
    "            # Same class, we walk d2 but we cut d2 rootpath (fullpath=False) since we will rebase on our own self.d dict\n",
    "            d2items = d2.viewitems(fullpath=False, nodes=False)  # ensure we do not add nodes, we need to rebuild anyway\n",
    "        elif isinstance(d2, dict):\n",
    "            # normal dict supplied\n",
    "            d2 = self.flatkeys(d2, sep=self.delimiter) # first, flatten the dict keys\n",
    "            d2items = self._genericitems(d2)\n",
    "        else:\n",
    "            raise ValueError('Supplied argument is not a dict.')\n",
    "\n",
    "        # Update our dict with d2 leaves\n",
    "        if self.rootpath:\n",
    "            # There is a rootpath, so user is selecting a sub dict (eg, d['item1']), so we need to reconstruct d2 with the full key path rebased on self.d before merging\n",
    "            rtncode = self.d.update((self._build_path(k), v) for k,v in d2items)\n",
    "        else:\n",
    "            # No rootpath, we can update directly because both dicts are comparable\n",
    "            if isinstance(d2, self.__class__):\n",
    "                rtncode = self.d.update(d2items)\n",
    "            else:\n",
    "                rtncode = self.d.update(d2)\n",
    "\n",
    "        # Fastview mode: we have to take care of nodes, since they are set(), they will get replaced and we might lose some pointers as they will all be replaced by d2's pointers, so we have to merge them separately\n",
    "        # The only solution is to skip d2 nodes altogether and rebuild the metadata for each new leaf added. This is faster than trying to merge separately each d2 set with self.d, because anyway we also have to rebuild for d2 root nodes (which might not be self.d root nodes particularly if rootpath is set)\n",
    "        if self.fastview:\n",
    "            self._build_metadata((self._build_path(k), v) for k,v in d2items)\n",
    "\n",
    "        return rtncode\n",
    "\n",
    "    def copy(self):\n",
    "        fcopy = self.__class__(d=self.d.copy(), rootpath=self.rootpath, delimiter=self.delimiter, fastview=self.fastview, **self.kwargs)\n",
    "        if self.fastview:\n",
    "            # Fastview mode: we need to ensure we have copies of every sets used for nodes, else the nodes will reference (delitem included) the same items in both the original and the copied fdict!\n",
    "            for k in fcopy._viewkeys():\n",
    "                if k.endswith(fcopy.delimiter):\n",
    "                    fcopy.d[k] = fcopy.d[k].copy()\n",
    "        return fcopy\n",
    "\n",
    "    @staticmethod\n",
    "    def _count_iter_items(iterable):\n",
    "        '''\n",
    "        Consume an iterable not reading it into memory; return the number of items.\n",
    "        by zuo: https://stackoverflow.com/a/15112059/1121352\n",
    "        '''\n",
    "        counter = itertools.count()\n",
    "        collections.deque(_zip(iterable, counter), maxlen=0)  # (consume at C speed)\n",
    "        return next(counter)\n",
    "\n",
    "    def __len__(self):\n",
    "        if not self.rootpath:\n",
    "            return self.d.__len__()\n",
    "        else:\n",
    "            # If there is a rootpath, we have to limit the length to the subelements\n",
    "            return self._count_iter_items(self.viewkeys())\n",
    "\n",
    "    def __eq__(self, d2):\n",
    "        is_d2fdict = isinstance(d2, self.__class__)\n",
    "        if is_d2fdict and not self.rootpath:\n",
    "            # fdict, we can directly compare\n",
    "            return (self.d == d2.d)\n",
    "        else:\n",
    "            kwargs = {}\n",
    "            if is_d2fdict:\n",
    "                if len(self) != len(d2):\n",
    "                    # If size is different then the dicts are different\n",
    "                    # Note that we need to compare the items because we need to filter if we are looking at nested keys (ie, if there is a rootpath)\n",
    "                    return False\n",
    "                else:\n",
    "                    kwargs['fullpath'] = False\n",
    "            elif isinstance(d2, dict): # normal dict, need to flatten it first\n",
    "                d2 = fdict.flatkeys(d2, sep=self.delimiter)\n",
    "                if len(self) != len(d2):\n",
    "                    return False\n",
    "\n",
    "            # Else size is the same, check each item if they are equal\n",
    "            # TOREMOVE COMMENT: There is a rootpath, this is a subdict, so we have to filter the items we compare (else we will compare the full dict to d2, which is probably not what the user wants if he does d['item1'] == d2)\n",
    "            if PY3:\n",
    "                d2items = d2.items(**kwargs)\n",
    "            else:\n",
    "                d2items = d2.viewitems(**kwargs)\n",
    "            for k, v in d2items:\n",
    "                fullkey = self._build_path(k)\n",
    "                if not fullkey in self.d or self.d.__getitem__(fullkey) != v:\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "    def __repr__(self):\n",
    "        # Filter the items if there is a rootpath and return as a new fdict\n",
    "        if self.rootpath:\n",
    "            return repr(self.__class__(d=dict(self.items()), rootpath='', delimiter=self.delimiter, fastview=self.fastview, **self.kwargs))\n",
    "        else:\n",
    "            try:\n",
    "                return self.d.__repr__()\n",
    "            except AttributeError as exc:\n",
    "                return repr(dict(self.items()))\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.rootpath:\n",
    "            return str(self.__class__(d=dict(self.items()), rootpath='', delimiter=self.delimiter, fastview=self.fastview, **self.kwargs))\n",
    "        else:\n",
    "            try:\n",
    "                return self.d.__str__()\n",
    "            except AttributeError as exc:\n",
    "                return str(dict(self.items()))\n",
    "\n",
    "    def to_dict(self):\n",
    "        '''Convert to a flattened dict'''\n",
    "        return dict(self.items())\n",
    "\n",
    "    def extract(self, fullpath=True):\n",
    "        '''Return a new fdict shortened to only the currently subselected items, but instead of fdict, should also support sfdict or any child class\n",
    "        It was chosen to return a fdict still containing the full keys and not the shortened ones because else it becomes very difficult to merge fdicts\n",
    "        And also for subdicts (like sfdict) which might store in a file, so we don't want to start mixing up different paths in the same file, but we would like to extract to a fdict with same parameters as the original, so keeping full path is the only way to do so coherently.\n",
    "        '''\n",
    "        if fullpath:\n",
    "            return self.__class__(d=self.items(fullpath=True), rootpath=self.rootpath, delimiter=self.delimiter, fastview=self.fastview, **self.kwargs)\n",
    "        else:\n",
    "            return self.__class__(d=self.items(fullpath=False), rootpath='', delimiter=self.delimiter, fastview=self.fastview) # , **self.kwargs)  # if not fullpath for keys, then we do not propagate kwargs because it might implicate propagating filename saving and mixing up keys. For fdict, this does not make a difference, but it might for subclassed dicts. Override this function if you want to ensure that an extract has all same parameters as original when fullpath=False in your subclassed dict.\n",
    "\n",
    "    def to_dict_nested(self):\n",
    "        '''Convert to a nested dict'''\n",
    "        d2 = {}\n",
    "        delimiter = self.delimiter\n",
    "        # Constuct the nested dict for each leaf\n",
    "        for k, v in self.viewitems(nodes=False):\n",
    "            # Get all parents of the current leaf, from root down to the leaf's direct parent\n",
    "            parents = self._get_all_parent_nodes_nested(k, delimiter)\n",
    "            # Recursively create each node of this subdict branch\n",
    "            d2sub = d2\n",
    "            for parent in parents:\n",
    "                if not parent in d2sub:\n",
    "                    # Create the node if it does not exist\n",
    "                    d2sub[parent] = {}\n",
    "                # Continue from this node\n",
    "                d2sub = d2sub[parent]\n",
    "            # get leaf key\n",
    "            k = k[k.rfind(delimiter)+1:]\n",
    "            # set leaf value\n",
    "            d2sub[k] = v\n",
    "        return d2\n",
    "\n",
    "\n",
    "class sfdict(fdict):\n",
    "    '''A nested dict with flattened internal representation, combined with shelve to allow for efficient storage and memory allocation of huge nested dictionnaries.\n",
    "    If you change leaf items (eg, list.append), do not forget to sync() to commit changes to disk and empty memory cache because else this class has no way to know if leaf items were changed!\n",
    "    '''\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Initialize specific arguments for sfdict\n",
    "        if not ('filename' in kwargs):\n",
    "            self.filename = tempfile.NamedTemporaryFile(delete=False).name\n",
    "        else:\n",
    "            self.filename = kwargs['filename']\n",
    "            #del kwargs['filename'] # do not del for auto management of internal sub calls to sfdict\n",
    "\n",
    "        if 'autosync' in kwargs:\n",
    "            self.autosync = kwargs['autosync']\n",
    "            #del kwargs['autosync']\n",
    "        else:\n",
    "            self.autosync = True\n",
    "\n",
    "        # Initialize parent class\n",
    "        fdict.__init__(self, *args, **kwargs)\n",
    "\n",
    "        # Replace internal dict with an out-of-core shelve\n",
    "        self.d = shelve.open(filename=self.filename, flag='c', writeback=True)\n",
    "\n",
    "        # Call compatibility layer\n",
    "        self._viewkeys, self._viewvalues, self._viewitems = self._getitermethods(self.d)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        fdict.__setitem__(self, key, value)\n",
    "        if self.autosync:\n",
    "            self.sync()\n",
    "\n",
    "    def get_filename(self):\n",
    "        if self.filename:\n",
    "            return self.filename\n",
    "        else:\n",
    "            return self.d.dict._datfile\n",
    "\n",
    "    def sync(self):\n",
    "        self.d.sync()\n",
    "\n",
    "    def close(self):\n",
    "        self.d.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- [x] pb of not creating sub fdict with all required arguments, like delimiter or filename for sfdict\n",
    "- [x] Nested contains: 'a' in d should return true if d['a/b'] exists\n",
    "- [x] Nested del eg d['a'] should del d[a/c/b] etc\n",
    "- [x] Update using d2.viewkeys et une loop pour set self.d[k] = self._build_path(d2[k] )\n",
    "- [x] unit test `__setitem__` fully\n",
    "- [x] Fastview store list of just this level of subitems paths , then recursively we can get the othersvif ends with /. We will have similar perfs to standard items at a small additional storage price. PROBLEM: same problem as above, will have to check for each level (we could use a set to ensure no duplicate but still...)\n",
    "- [x] Finish fastview:\n",
    "  * [x] del\n",
    "  * [x] contains\n",
    "  * [x] setitem of nested dicts\n",
    "  * [x] setitem replacing existing leaf/node\n",
    "- [x] to_dict_nested()\n",
    "- [ ] benchmarks\n",
    "- [ ] setup.py\n",
    "- [ ] travis py3\n",
    "- [ ] docstring init with arguments, like tqdm\n",
    "- [ ] readme\n",
    "- [ ] pypi (use pymake?)\n",
    "- [ ] codacy, coverage, badge version, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unit testing\n",
    "\n",
    "# Test creation of just a nested dict, without anything else\n",
    "a = fdict()\n",
    "a['c']['b'] = set([1, 2])\n",
    "assert a == {'c/b': set([1, 2])}\n",
    "\n",
    "# Basic test\n",
    "a = fdict()\n",
    "a['a'] = {}\n",
    "a['c']['b'] = set([1, 2])\n",
    "\n",
    "assert a.keys() == ['c/b']\n",
    "assert a.items() == [('c/b', set([1, 2]))]\n",
    "\n",
    "# Copy test\n",
    "acopy = a.copy()\n",
    "assert acopy.items() == a.items()\n",
    "assert acopy is not a\n",
    "\n",
    "# Referencing into another variable of a nested item + check update of nested items\n",
    "b = acopy['c']\n",
    "assert b.items() == [('b', set([1, 2]))]\n",
    "acopy['c'].update({'d': 3})\n",
    "assert acopy == {'c/b': set([1, 2]), 'c/d': 3}\n",
    "assert b == {'b': set([1, 2]), 'd': 3}\n",
    "\n",
    "# Other tests\n",
    "d = fdict()\n",
    "d['b'] = {'a': 1} # test subitem assignment of a dict\n",
    "d['c/b'] = set([2, 3, 5])\n",
    "assert d.to_dict() == {'c/b': set([2, 3, 5]), 'b/a': 1}\n",
    "\n",
    "a.update(d)\n",
    "assert a.to_dict() == {'c/b': set([2, 3, 5]), 'b/a': 1}\n",
    "assert a['c'].to_dict() == {'b': set([2, 3, 5])}\n",
    "\n",
    "# Sfdict test\n",
    "g = sfdict(filename='testshelf')\n",
    "g['a'] = 3\n",
    "g['b/c'] = set([1, 3, 4])\n",
    "g['d'] = {}\n",
    "assert g == {'a': 3, 'b/c': set([1, 3, 4])}\n",
    "assert g == {'a': 3, 'b/c': set([1, 3, 4]), 'd': {}} # empty dicts are stripped out before comparison\n",
    "assert g['b'].filename == g.filename # check that subdicts also share the same filename (parameters propagation)\n",
    "\n",
    "# Sfdict reloading test\n",
    "h = sfdict(filename='testshelf')\n",
    "assert h == g\n",
    "g.close()\n",
    "h.close()\n",
    "\n",
    "# Flattening test\n",
    "m = {}\n",
    "m['a'] = 1\n",
    "m['b'] = {'c': 3, 'd': {'e': 5}}\n",
    "m['f'] = set([1, 2, 5])\n",
    "m2 = fdict(m)\n",
    "assert dict(m2.items()) == fdict.flatkeys(m)\n",
    "\n",
    "# Update and extract test\n",
    "n = {}\n",
    "n['b'] = {'d': {'f': 6}}\n",
    "n['g'] = 7\n",
    "m2.update(n)\n",
    "assert m2 == {'a': 1, 'g': 7, 'b/c': 3, 'b/d/e': 5, 'b/d/f': 6, 'f': set([1, 2, 5])}\n",
    "\n",
    "assert m2['b'].d == m2.d\n",
    "assert m2['b'].extract().d == {'b/c': 3, 'b/d/e': 5, 'b/d/f': 6}\n",
    "\n",
    "# len() test\n",
    "assert len(m2) == 6\n",
    "assert len(m2['b']) == 3\n",
    "assert len(m2['b']['d']) == len(m2['b/d']) == 2\n",
    "assert not hasattr(m2['g'], '__len__') and isinstance(m2['g'], int)\n",
    "\n",
    "# Extract extended test\n",
    "a10 = fdict()\n",
    "a10['c/b/d'] = set([1, 2])\n",
    "assert a10['c'].extract(fullpath=True).d == {'c/b/d': {1, 2}}\n",
    "assert a10['c'].extract(fullpath=True) == {'b/d': {1, 2}}\n",
    "assert a10['c'].extract(fullpath=False).d == {'b/d': {1, 2}}\n",
    "\n",
    "# Contains test\n",
    "p=fdict()\n",
    "p['a/b/c'] = set([1, 2])\n",
    "p['a/c'] = 3\n",
    "p['a/d'] = {'e': {'f': 4}, 'g': 5}\n",
    "p['h'] = 6\n",
    "assert 'h' in p # check existence of a leaf (O(1))\n",
    "assert 'a/b/c' in p # check existence of a nested leaf (O(1))\n",
    "assert 'a/b' in p # check existence of a nested dict (O(n))\n",
    "\n",
    "# Del test\n",
    "p=fdict()\n",
    "p['a/b/c'] = set([1, 2])\n",
    "p['a/c'] = 3\n",
    "p['a/d'] = {'e': {'f': 4}, 'g': 5}\n",
    "p['h'] = 6\n",
    "p2 = p.copy()\n",
    "assert 'h' in p # check existence of a leaf (O(1))\n",
    "assert 'a/b/c' in p # check existence of a nested leaf (O(1))\n",
    "assert 'a/b' in p # check existence of a nested dict (O(n))\n",
    "del p['a/b/c']\n",
    "del p2['a']['b']['c']  # test both types of access (fullpath or by subselection)\n",
    "assert p == p2 == {'h': 6, 'a/d/e/f': 4, 'a/c': 3, 'a/d/g': 5}\n",
    "del p['h']\n",
    "del p2['h']\n",
    "assert p == p2 == {'a/d/e/f': 4, 'a/c': 3, 'a/d/g': 5}\n",
    "del p['a/d']\n",
    "del p2['a']['d']\n",
    "assert p == p2 == {'a/c': 3}\n",
    "try:\n",
    "    # Delete inexistent key\n",
    "    del p['a']['b']['x']\n",
    "except KeyError as exc:\n",
    "    assert True\n",
    "else:\n",
    "    assert False\n",
    "\n",
    "\n",
    "# Update test and equality test\n",
    "a1 = {'a': set([1, 2]), 'b': {'c': 3, 'c2': 4}, 'd': 4}\n",
    "b1 = {'a': set([1, 2, 3]), 'b': {'c': 4, 'c3': 3}, 'e': 5}\n",
    "a2 = fdict(a1)\n",
    "b2 = fdict(b1)\n",
    "a11 = a1.copy()\n",
    "a12 = a1.copy()\n",
    "a13 = a1.copy()\n",
    "a14 = a1.copy()\n",
    "a15 = a1.copy()\n",
    "a21 = a2.copy()\n",
    "a22 = a2.copy()\n",
    "a23 = a2.copy()\n",
    "a24 = a2.copy()\n",
    "a25 = a2.copy()\n",
    "\n",
    "# no rootpath (ie, use whole dicts)\n",
    "a11.update(b1)\n",
    "a21.update(b2)\n",
    "assert a11 == {'a': set([1, 2, 3]), 'b': {'c3': 3, 'c': 4}, 'e': 5, 'd': 4}\n",
    "assert a21 == {'a': set([1, 2, 3]), 'b/c': 4, 'b/c2': 4, 'b/c3': 3, 'e': 5, 'd': 4} # by default, fdict supports recursive update (eg, c2 is kept here)\n",
    "\n",
    "# update a subdict with a subdict\n",
    "a12['b'].update(b1['b'])\n",
    "a22['b'].update(b2['b'])\n",
    "assert a12 == {'a': set([1, 2]), 'b': {'c3': 3, 'c2': 4, 'c': 4}, 'd': 4}\n",
    "assert a22 == {'a': set([1, 2]), 'b/c': 4, 'b/c2': 4, 'b/c3': 3, 'd': 4}\n",
    "assert a22 == a12\n",
    "assert len(a22) == 5 # len() test\n",
    "\n",
    "# update of a subdict with a whole dict (extracted subdict)\n",
    "a13['b'].update(b1['b'])\n",
    "b2sub = b2['b'].extract()\n",
    "a23['b'].update(b2sub)\n",
    "b2sub == {'c': 4, 'c3': 3}\n",
    "assert b2sub == {'c': 4, 'c3': 3}\n",
    "assert a23 == a22\n",
    "assert b2['b'].rootpath == b2sub.rootpath # rootpath is kept after extract\n",
    "assert b2['b'].d == b2.d # dict of a sub fdict is the same as the root fdict's dict\n",
    "assert dict(b2['b'].items()) == dict(b2sub.items())\n",
    "assert dict(b2['b'].items(fullpath=True)) == dict(b2sub.items(fullpath=True)) == b2sub.d # but the items (filtered by rootpath) will be different\n",
    "\n",
    "# update of a subdict with a whole dict (REALLY extracted subdict, rootpath is lost, so it is just like a new fdict)\n",
    "a14['b'].update(b1['b'])\n",
    "b2sub_orig = b2['b'].extract(fullpath=False)\n",
    "for b2sub in [b2sub_orig.to_dict(), b2sub_orig]:\n",
    "    # This test should pass with both a dict and a fdict\n",
    "    a24c = a24.copy()\n",
    "    a24c['b'].update(b2sub)\n",
    "    b2sub == {'c': 4, 'c3': 3}\n",
    "    assert b2sub == {'c': 4, 'c3': 3}\n",
    "    assert a24c == a22\n",
    "    assert b2['b'].rootpath == 'b'\n",
    "    assert not b2sub_orig.rootpath # rootpath is lost after extract(fullpath=False) (so it is like creating a new fdict)\n",
    "    assert b2['b'].d == b2.d # dict of a sub fdict is the same as the root fdict's dict\n",
    "    assert dict(b2['b'].items()) == dict(b2sub.items())\n",
    "    assert dict(b2['b'].items(fullpath=False)) == dict(b2sub_orig.items(fullpath=True)) == b2sub_orig.d # but the items (filtered by rootpath) will be different\n",
    "\n",
    "# update of whole dict (extracted subdict) with subdict\n",
    "a15sub = a15['b']\n",
    "a15sub.update(b1['b'])\n",
    "a25sub = a25['b'].extract(fullpath=False)\n",
    "a25subc = a25sub.copy()\n",
    "a25sub.update(b2['b'])\n",
    "a25subc.update(b2['b'].extract(fullpath=False))\n",
    "assert a15sub == a25sub == a25subc\n",
    "assert a15sub.items() == a25sub.items() == a25subc.items()\n",
    "\n",
    "# Test emptying by setitem to empty dict and singleton replacement by a nested dict\n",
    "a = fdict({'a/b': 1, 'a/c': set([1,2,3]), 'd': [1, 2, 3], 'e': [1, 2, 3]})\n",
    "# emptying by setitem with empty dict\n",
    "a['d'] = {}\n",
    "assert a == {'a/c': set([1, 2, 3]), 'a/b': 1, 'e': [1, 2, 3]}\n",
    "# replace singleton with a dict\n",
    "a['e'] = {'f': 2, 'g': 3}\n",
    "assert a == {'a/c': set([1, 2, 3]), 'a/b': 1, 'e/g': 3, 'e/f': 2}\n",
    "# replace dict with a singleton (does not work, both will coexist)\n",
    "a['a'] = 2\n",
    "assert a == {'a': 2, 'a/c': set([1, 2, 3]), 'a/b': 1, 'e/g': 3, 'e/f': 2}\n",
    "\n",
    "# Test to_dict_nested() conversion\n",
    "a = fdict({'a/b': 1, 'a/c': set([1, 2]), 'd': 3})\n",
    "adict = a.to_dict_nested()\n",
    "assert adict == {'a': {'b': 1, 'c': {1, 2}}, 'd': 3}\n",
    "assert not isinstance(adict, fdict) and isinstance(adict, dict)\n",
    "\n",
    "# Test update of empty subdict\n",
    "a = fdict()\n",
    "a['a'] = {}\n",
    "a['a'].update({'b': 1, 'c': 2})\n",
    "assert a == {'a/c': 2, 'a/b': 1}\n",
    "\n",
    "# Test fastview mode\n",
    "a = fdict(fastview=True)\n",
    "a['a/b/c'] = 1\n",
    "a['a']['b']['d'] = 2\n",
    "a['a']['e']['f'] = 3\n",
    "a['a']['e']['g']['h'] = 4\n",
    "a['a']['e']['g']['i'] = 5\n",
    "\n",
    "assert a.d.items() == [('a/e/g/', set(['a/e/g/i', 'a/e/g/h'])), ('a/e/f', 3), ('a/e/', set(['a/e/g/', 'a/e/f'])), ('a/', set(['a/e/', 'a/b/'])), ('a/b/c', 1), ('a/b/d', 2), ('a/b/', set(['a/b/c', 'a/b/d'])), ('a/e/g/i', 5), ('a/e/g/h', 4)]\n",
    "assert a.items() == [('a/e/f', 3), ('a/b/c', 1), ('a/b/d', 2), ('a/e/g/i', 5), ('a/e/g/h', 4)]  # items() on a fastview fdict should hide the nodes (eg, 'a/b/') and only show leafs, so that behavior is comparable to a non-fastview fdict\n",
    "assert a['a']['e'].items() == [('g/i', 5), ('g/h', 4), ('f', 3)]\n",
    "assert a['a']['e'].items(fullpath=True) == [('a/e/g/i', 5), ('a/e/g/h', 4), ('a/e/f', 3)]  # test recursive fastview items()\n",
    "\n",
    "assert a['a']['e'].items(fullpath=True) == [('a/e/g/i', 5), ('a/e/g/h', 4), ('a/e/f', 3)]\n",
    "assert a['a']['e'].keys(fullpath=True) == ['a/e/g/i', 'a/e/g/h', 'a/e/f']\n",
    "assert set(a['a']['e'].values()) == set([5, 4, 3])\n",
    "assert set(a['a'].values()) == set([1, 2, 3, 4, 5])  # use set() when we do not case about order in a list\n",
    "assert a['j'].items() == []  # empty nested dict\n",
    "assert a['j'].keys() == []\n",
    "assert a['j'].values() == []\n",
    "\n",
    "# test fastview contains\n",
    "assert 'a' in a\n",
    "assert 'a/' in a\n",
    "assert 'a/e/g/h' in a\n",
    "assert 'g' in a['a']['e']\n",
    "assert 'g' in a['a/e']\n",
    "assert 'g/h' in a['a/e']\n",
    "assert not 'a/e/g/x' in a\n",
    "assert not 'x' in a\n",
    "\n",
    "# test fastview copy\n",
    "from copy import deepcopy\n",
    "assert a == {'a/e/g/': set(['a/e/g/i', 'a/e/g/h']), 'a/e/f': 3, 'a/e/': set(['a/e/g/', 'a/e/f']), 'a/': set(['a/e/', 'a/b/']), 'a/b/c': 1, 'a/b/d': 2, 'a/b/': set(['a/b/c', 'a/b/d']), 'a/e/g/i': 5, 'a/e/g/h': 4}\n",
    "a2 = a.copy()\n",
    "for k in a.d.keys():\n",
    "    if k.endswith(a.delimiter):\n",
    "        # all nodes should be copied as different objects\n",
    "        assert id(a.d[k]) != id(a2.d[k])\n",
    "a3 = deepcopy(a)\n",
    "for k in a.d.keys():\n",
    "    # with a deep copy, all items (not just nodes) should be copied as different objects\n",
    "    if hasattr(a.d[k], '__len__'):  # compare only collections (because for scalars we can't know if Python caches, or at least I did not find how to check that)\n",
    "        assert id(a.d[k]) != id(a3.d[k])  # could replace by equivalent: a.d[k] is not a3.d[k]\n",
    "# check that a is unchanged after copy\n",
    "assert a == {'a/e/g/': set(['a/e/g/i', 'a/e/g/h']), 'a/e/f': 3, 'a/e/': set(['a/e/g/', 'a/e/f']), 'a/': set(['a/e/', 'a/b/']), 'a/b/c': 1, 'a/b/d': 2, 'a/b/': set(['a/b/c', 'a/b/d']), 'a/e/g/i': 5, 'a/e/g/h': 4}\n",
    "\n",
    "# test fastview del\n",
    "a == fdict({'a/e/g/': set(['a/e/g/i', 'a/e/g/h']), 'a/e/f': 3, 'a/e/': set(['a/e/g/', 'a/e/f']), 'a/': set(['a/e/', 'a/b/']), 'a/b/c': 1, 'a/b/d': 2, 'a/b/': set(['a/b/c', 'a/b/d']), 'a/e/g/i': 5, 'a/e/g/h': 4}, fastview=True)\n",
    "a2 = a.copy()\n",
    "# leaf deletion\n",
    "assert a['a'].keys(fullpath=True, nodes=True) == ['a/e/', 'a/e/g/', 'a/b/', 'a/b/c', 'a/b/d', 'a/e/f', 'a/e/g/i', 'a/e/g/h']\n",
    "del a['a/e/g/h']\n",
    "del a2['a']['e']['g']['h']\n",
    "assert a == a2 == {'a/e/g/': set(['a/e/g/i']), 'a/e/f': 3, 'a/e/': set(['a/e/g/', 'a/e/f']), 'a/': set(['a/e/', 'a/b/']), 'a/b/c': 1, 'a/b/d': 2, 'a/b/': set(['a/b/c', 'a/b/d']), 'a/e/g/i': 5}\n",
    "assert 'a/e/g/h' not in a['a'].keys(fullpath=True, nodes=True)\n",
    "# node deletion\n",
    "assert a['a/e'].keys() == a2['a']['e'].keys() == ['g/i', 'f']\n",
    "assert a['a/e'].keys(nodes=True) == a['a']['e'].keys(nodes=True) == ['g/', 'g/i', 'f']\n",
    "del a['a/e']\n",
    "del a2['a']['e']\n",
    "assert a == a.d == a2 == a2.d == {'a/': set(['a/b/']), 'a/b/c': 1, 'a/b/d': 2, 'a/b/': set(['a/b/c', 'a/b/d'])}\n",
    "assert not a['a/e'].keys() and not a2['a']['e']\n",
    "assert a['a'].keys(fullpath=True, nodes=True) == ['a/b/', 'a/b/d', 'a/b/c']\n",
    "\n",
    "# test fastview nodes metadata creation with nested dicts and at creation\n",
    "a = fdict({'a/b': 1, 'a/c': set([1,2,3]), 'd': [1, 2, 3]}, fastview=True)\n",
    "# add nested dict\n",
    "a['g'] = {'h': {'i': {'j': 6}, 'k': 7}, 'l': 8}\n",
    "assert a.d == {'g/l': 8, 'g/h/i/j': 6, 'g/h/i/': set(['g/h/i/j']), 'a/': set(['a/b', 'a/c']), 'a/c': set([1, 2, 3]), 'a/b': 1, 'g/h/': set(['g/h/k', 'g/h/i/']), 'g/': set(['g/l', 'g/h/']), 'g/h/k': 7, 'd': [1, 2, 3]}\n",
    "\n",
    "# test fastview setitem replacement of singleton by nested dict and inversely + delitem\n",
    "a = fdict({'a/b': 1, 'a/c': set([1,2,3]), 'd': [1, 2, 3]}, fastview=True)\n",
    "# singleton to nested dict\n",
    "a['d/e'] = 4\n",
    "a['d/f'] = 5\n",
    "assert ('d', [1, 2, 3]) not in a.viewitems(nodes=True)\n",
    "# nested dict to singleton\n",
    "a['a'] = 2\n",
    "# add nested dict (and check metadata creation for each parent of nested leaves in the nested dict)\n",
    "a['g'] = {'h': {'i': {'j': 6}, 'k': 7}, 'l': 8}\n",
    "assert a['a'] == 2\n",
    "# delitem singleton\n",
    "del a['g/h/i/j']\n",
    "assert a.d == {'a': 2, 'd/': set(['d/f', 'd/e']), 'g/l': 8, 'd/f': 5, 'd/e': 4, 'g/h/': set(['g/h/k']), 'g/': set(['g/l', 'g/h/']), 'g/h/k': 7}\n",
    "# delitem nested dict\n",
    "del a['d']\n",
    "assert a.d == {'a': 2, 'g/l': 8, 'g/h/': set(['g/h/k']), 'g/': set(['g/l', 'g/h/']), 'g/h/k': 7}\n",
    "\n",
    "print('All unit tests passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### BENCHMARKS\n",
    "try:\n",
    "    _range = xrange\n",
    "except NameError as exc:\n",
    "    _range = range\n",
    "\n",
    "def benchmark_set(dclass, breadth=5, depth=1000, args=None, kwargs=None):\n",
    "    d = dclass(*args, **kwargs)\n",
    "    di = d\n",
    "    for i in _range(depth):\n",
    "        for j in _range(breadth):\n",
    "            d[str(j)] = j\n",
    "        di = d[str(j)]\n",
    "    return d\n",
    "\n",
    "def benchmark_get(dclass, breadth=5, depth=1000, args=None, kwargs=None):\n",
    "    d = benchmark_set(dclass, breadth=breadth, depth=depth, args=args, kwargs=kwargs)\n",
    "    di = d\n",
    "    x = None\n",
    "    for i in _range(depth):\n",
    "        for j in _range(breadth):\n",
    "            x = d[str(j)]\n",
    "        di = d[str(j)]\n",
    "    return x\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
